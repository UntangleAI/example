{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation for Signal Estimation and Attribution\n",
    "\n",
    "Once we use UntangleAI's uncertainty estimation, we would like to know why the model's decision is uncertain regarding those test points. Some relevant questions one could have at this point in time are\n",
    " - What are the salient fetuares in the input that model is relying upon, to make its decision?\n",
    " - What are the relative importance given to these fetures by the model to frame its decision?\n",
    " - How robust is the model for adversarial attacks? Is it possible to change input slightly to get drastically different model decisions?\n",
    " \n",
    " As part of UntangleAI Signal Estimation service, we provide these insights about the model and a way to visulaize the decision process of the model for computer vision applications. This service tries to saperate out signal componenet from the noise in the trianing data and learns for each class what signal/feautres model is learning and what else it discards as noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 Training a CNN for recognizing MNIST dataset\n",
    "\n",
    "This step is optional. If you would like to train a CNN network to recognize MNIST dataset you can refer to [this tutorial](/tutorials/mnist_model_training) which trains a model for 10 epochs and saves the trained weights into lenet_mnist_model.h5\n",
    "\n",
    "Or you can download the trained weights from [here](https://untanglemodels.s3.amazonaws.com/lenet_mnist_model.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Signal Estimation for each class\n",
    "\n",
    "During this phase, we take the trained model and training data set batched by class and estimate signals that model has learned during its training phase for each class and generate signal estimation statistics for each class and save them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "torch.set_printoptions(precision=8)\n",
    "from untangle import UntangleAI\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from the trained or downloaded checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the same model used for training\n",
    "class LeNet(nn.Module):\n",
    "    # TODO: This isn't really a LeNet, but we implement this to be\n",
    "    #  consistent with the Evidential Deep Learning paper\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.model = None\n",
    "        lenet_conv = []\n",
    "        lenet_conv += [torch.nn.Conv2d(1,20, kernel_size=(5,5))]\n",
    "        lenet_conv += [torch.nn.ReLU(inplace=True)]\n",
    "        lenet_conv += [torch.nn.MaxPool2d(kernel_size=(2,2), stride=2)]\n",
    "        lenet_conv += [torch.nn.Conv2d(20, 50, kernel_size=(5,5))]\n",
    "        lenet_conv += [torch.nn.ReLU(inplace=True)]\n",
    "        lenet_conv += [torch.nn.MaxPool2d(kernel_size=(2,2), stride=2)]\n",
    "\n",
    "        lenet_dense = []\n",
    "        lenet_dense += [torch.nn.Linear(4*4*50, 500)]\n",
    "        lenet_dense += [torch.nn.ReLU(inplace=True)]\n",
    "        lenet_dense += [torch.nn.Linear(500, 10)]\n",
    "\n",
    "        self.features = torch.nn.Sequential(*lenet_conv)\n",
    "        self.classifier = torch.nn.Sequential(*lenet_dense)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.features(input)\n",
    "        output = output.view(input.shape[0], -1)\n",
    "        output = self.classifier(output)\n",
    "        return(output)\n",
    "    \n",
    "model_ckpt_path = 'lenet_mnist_model.h5'\n",
    "model = LeNet()\n",
    "if (torch.cuda.is_available()):\n",
    "    ckpt = torch.load(model_ckpt_path)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    ckpt = torch.load(model_ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(ckpt)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define argruments needed for signal estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalEstimationArgs:\n",
    "    mname = 'lenet'\n",
    "    batch_size = 16\n",
    "    num_classes = 10\n",
    "    img_size = (1,28,28)\n",
    "    input_tensor = torch.randn(1,1,28,28) # provide your own input tensor\n",
    "    input_tensor_true = torch.randn(28,28,1) # provide your own true input tensor / ndarray / PIL Image Obj\n",
    "    data_class = None # or `None` to estimate all classes\n",
    "    mode = 'estimate' # one of `estimate`, `attribute`\n",
    "    topk = 1\n",
    "    cmap = 'seismic'\n",
    "    json = False\n",
    "    hm_diff = 'joint'\n",
    "    \n",
    "args = SignalEstimationArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required directories to store estimated signal statistics which will be used later to attribute signals for a given test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.dirname(os.path.realpath('.'))\n",
    "proj_path = os.path.abspath(os.path.join(module_path, os.pardir))\n",
    "model_signal_data_path = os.path.join(module_path, 'model_signal_data/')\n",
    "results_path = os.path.join(module_path, 'results')\n",
    "if(not os.path.exists(model_signal_data_path)):\n",
    "    os.makedirs(model_signal_data_path)\n",
    "if(not os.path.exists(results_path)):\n",
    "    os.makedirs(results_path)\n",
    "signal_store_path = os.path.join(model_signal_data_path, '{}_signals'.format(args.mname))\n",
    "\n",
    "\n",
    "# Create untangle object\n",
    "untangle_ai = UntangleAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call untangle API (estimate_signals) to learn and store signal estimation statistics. Provide a data loader which loads the training dataset class by class. For MNIST we have provided an api for the same, which is load_mnist_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_loader_fun(class_i):\n",
    "    loader, _ = untangle_ai.load_mnist_per_class(batch_size=args.batch_size, data_class=class_i)\n",
    "    return(loader)\n",
    "\n",
    "untangle_ai.estimate_signals(model, signal_store_path, train_loader_fun, args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Attributing signals for a test point\n",
    "\n",
    "Now we use the signal statistics modelled in Step 1 to attribute and visualize the signals for an input test point.\n",
    "\n",
    "We use untangle_ai API (attribute_signals) to get signal information and visulaization with respect to top k class of model prediction. We also generate a joint heatmap and differentail heatmap images for the top k classes as part of this API.\n",
    "\n",
    "This api works on individual data points one at a time. It takes input_tensor and image_tensor as (Height, Width, Channel) as its shape as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to visualize signal/feature considered important for a random data point. We visualize heatmap, differential heat map and inverse differential heatmap for top 3 classes predicted by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "keys = [str(item) for item in range(args.num_classes)]\n",
    "ID2Name_Map = dict(zip(keys, keys))\n",
    "rand_class = random.randint(0, 9)\n",
    "print('Visualizing signal for a data point in class {}'.format(rand_class))\n",
    "rand_class_loader = train_loader_fun(rand_class)\n",
    "for input_tensor, _ in rand_class_loader:\n",
    "    idx = random.randint(0, input_tensor.shape[0]-1)\n",
    "    for topk in range(1, 4): # Try to get diff heatmap for top 3 classes\n",
    "        args.topk = topk   \n",
    "        input_tensor_single = input_tensor[idx][None, :, :, :]\n",
    "        input_tensor_true = input_tensor[idx].permute(1, 2, 0) # expected shape (H,W,C)\n",
    "        out_prefix = os.path.join(results_path, '{}_signals'.format(idx))\n",
    "        untangle_ai.attribute_signals(model, input_tensor_single, input_tensor_true, signal_store_path,\n",
    "            ID2Name_Map, args, out_prefix)\n",
    "        for i in range(topk):\n",
    "            img = imread(out_prefix + '_class_{}.JPEG'.format(i))\n",
    "            print('Visualizing {}'.format(out_prefix + '_class_{}.JPEG'.format(i)))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        for i in range(1, topk):\n",
    "            img = imread(out_prefix + '_diff_class_{}.JPEG'.format(i))\n",
    "            print('Visualizing {}'.format(out_prefix + '_diff_class_{}.JPEG'.format(i)))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            img = imread(out_prefix + '_invDiff_class_{}.JPEG'.format(i))\n",
    "            print('Visualizing {}'.format(out_prefix + '_invDiff_class_{}.JPEG'.format(i)))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
