{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Explanation Methods | API Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Vanilla Gradient Descent Method\n",
    "Explains the model prediction by observing the gradient, $\\nabla_{\\textbf{X}_i} O_k$, of output prediction, $O_k \\in \\textit{class-k}$ w.r.t the input $\\textbf{X}_i$\n",
    "\n",
    "### [2] DeConvNet Method\n",
    "[DeConvNet](https://arxiv.org/abs/1311.2901) inverts the data flow from higher feature maps back to the input image. Specifically, given a non-zero neuron at a higher layer, inverting the data flow shows parts of the input image that most strongly activate this neuron.\n",
    "\n",
    "### [3] Guided Backprop\n",
    "[Guided BackProp](https://arxiv.org/abs/1412.6806) builds on [DeConvNet](https://arxiv.org/abs/1311.2901) explanation method where negative gradients are set to zero while backpropagating through a ReLu input.\n",
    "\n",
    "### [4] GradCAM\n",
    "[GradCAM](https://arxiv.org/abs/1610.02391) explanations correspond to the gradient of the class score (logit) with respect to the feature map of the last convolutional unit of a DNN. This gradient signal is then resized to the original input dimension usng suitagle interpolation technique.\n",
    "\n",
    "### [5] saliencyGrad\n",
    "Saliency Grad is defined as the absolute value of the gradient of class prediction w.r.t the input\n",
    "\n",
    "### [6] integratedGrad\n",
    "[Integrated Gradients](https://arxiv.org/abs/1703.01365), $IG(x)$ for a given input $x$ helps in reducing the saturation in gradients by summing over scaled version of the input.\n",
    "\n",
    "$$IG(x_i) = x_i - (x_0)_i * \\int_{\\alpha=0}^{1} \\frac{\\partial F( (x_0)_i + \\alpha * (x_i - (x_0)_i)  )}{\\partial x_i} \\textit{d}\\alpha  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls\n",
    "\n",
    "`untangle_ai.methodName(model, input_tensor, input_img, out_prefix, args)`\n",
    "\n",
    "Where `methodName` is one of `vanillaGrad`, `deConvNet`, `guided_bp`, `gradcam`, `saliencyGrad`, `integratedGrad`\n",
    "\n",
    "### Parameters\n",
    "* `model`: PyTorch model object (callable)\n",
    "* `input_tensor`: a 4-tuple normalized torch input tensor of shape (B,C,H,W)\n",
    "* `input_img`: raw input tensor - one of PIL Image obj / ndarray / torch tensor, of shape (HWC)\n",
    "* `out_prefix`: prefix to save heatmaps, `default = vanillaGrad_heatmaps`\n",
    "* `args`: an instance of `class Args` containing required parameters. Refer to [this tutorial]() for an example\n",
    "\n",
    "### Returns\n",
    "* `None`\n",
    "* If `args.json=False`, saves the heatmaps as `JPG` images, else, saves the gradients as a `json` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [7] SmoothGrad\n",
    "[SmoothGrad](https://arxiv.org/pdf/1706.03825.pdf) is a meta algorithm that sits on top of a given gradient explanation method. It tries to suppress noise in the gradients by averaging gradients across multiple noisy versions of the input. For a given input $\\pmb{x}$, the smoothGrad gradient, $SG(\\pmb{x})$ is given by:\n",
    "\n",
    "$$SG(\\pmb{x}) = \\sum_{i=1}^n \\nabla_{\\pmb{x} + g_i} O_k$$ where $\\pmb{g}_i \\sim \\mathcal{N}(\\mu,\\sigma^2)$ are drawn i.i.d from a Normal distribution.\n",
    "\n",
    "`untangle_ai.smoothgrad(model, base_explainer, input_tensor, input_img, out_prefix, args)`\n",
    "\n",
    "### Parameters\n",
    "* `model`: PyTorch model object (callable)\n",
    "* `base_explainer`: one of `vanillaGrad`, `deConvNet`, `guided_bp`, `gradcam`, `saliencyGrad`, `integratedGrad`\n",
    "* `input_tensor`: a 4-tuple normalized torch input tensor of shape (B,C,H,W)\n",
    "* `input_img`: raw input tensor - one of PIL Image obj / ndarray / torch tensor, of shape (HWC)\n",
    "* `out_prefix`: prefix to save heatmaps, `default = vanillaGrad_heatmaps`\n",
    "* `args`: an instance of `class Args` containing required parameters. Refer to [this tutorial]() for an example\n",
    "\n",
    "### Returns\n",
    "* `None`\n",
    "* If `args.json=False`, saves the heatmaps as `JPG` images, else, saves the gradients as a `json` object\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
